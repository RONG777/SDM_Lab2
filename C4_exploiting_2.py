import numpy as np
from ampligraph.datasets import load_from_csv
from ampligraph.latent_features import ScoringBasedEmbeddingModel
from ampligraph.compat import evaluate_performance
from ampligraph.evaluation import mrr_score, hits_at_n_score
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.linear_model import LogisticRegression


# ——— Configuration ———
TRAIN_FILE  = "train.tsv"
VALID_FILE  = "valid.tsv"
TEST_FILE   = "test.tsv"
EPOCHS      = 200
BATCHES     = 150
PCA_DIM     = 20
K_MIN, K_MAX= 3, 10
MODEL_PATH  = "complEx_best_model.pkl"
CLUST_OUT   = "author_clusters_ag2.csv"

# ——— Load splits ———
X_train_raw = load_from_csv(".", TRAIN_FILE, sep="\t")
X_valid_raw = load_from_csv(".", VALID_FILE, sep="\t")
X_test_raw  = load_from_csv(".", TEST_FILE,  sep="\t")

# —– Build vocab from train —–
all_ents = np.concatenate([
    X_train_raw[:, 0].astype(str),
    X_train_raw[:, 2].astype(str)
])
mask = all_ents != 'nan'
ents = np.unique(all_ents[mask])
rels = np.unique(X_train_raw[:, 1])

ent_to_idx = {e: i for i, e in enumerate(ents)}
rel_to_idx = {r: i for i, r in enumerate(rels)}

# —– Helper to map and filter triples —–
def map_and_filter(X_raw):
    mapped = []
    for h, r, t in X_raw:
        if h in ent_to_idx and r in rel_to_idx and t in ent_to_idx:
            mapped.append([ent_to_idx[h], rel_to_idx[r], ent_to_idx[t]])
    return np.array(mapped, dtype=int)

X_train = map_and_filter(X_train_raw)
X_valid = map_and_filter(X_valid_raw)
X_test  = map_and_filter(X_test_raw)

# ——— 1) Train best KGE (ComplEx) ———
print("Training ComplEx | dim=100 | negs=5")
model = ScoringBasedEmbeddingModel(eta=5, k=100, scoring_type="ComplEx", seed=0)
model.compile(optimizer='adam', loss='pairwise')
batch_size = max(1, X_train.shape[0] // BATCHES)
model.fit(X_train, batch_size=batch_size, epochs=EPOCHS, verbose=False)

# Evaluate on validation
ranks = evaluate_performance(X_valid, model=model, filter_triples=X_train, corrupt_side='s,o', batch_size=256)
mrr, h10 = mrr_score(ranks), hits_at_n_score(ranks, 10)
print(f"Validation → MRR={mrr:.4f}, Hits@10={h10:.4f}")

# Evaluate on test
ranks_test = evaluate_performance(X_test, model=model, filter_triples=X_train, corrupt_side='s,o', batch_size=256)
mrr_t, h10_t = mrr_score(ranks_test), hits_at_n_score(ranks_test, 10)
print(f"Test       → MRR={mrr_t:.4f}, Hits@10={h10_t:.4f}")

# Prepare classification dataset
# Positives: test triples
pos = X_test.copy()
# Negatives: corrupt tail for each positive
negs = []
all_ents = np.unique(np.concatenate([X_train[:,0], X_train[:,2]]))
for h, r, t in pos:
    corrupt = t
    while corrupt == t:
        corrupt = np.random.choice(all_ents)
    negs.append([h, r, corrupt])
negs = np.array(negs)

# Combine and label
X_cls = np.vstack([pos, negs])
y = np.hstack([np.ones(len(pos)), np.zeros(len(negs))])

# Score triples using the KGE model
# ScoringBasedEmbeddingModel.predict returns scores (higher = more plausible)
scores_pos = model.predict(pos)
scores_neg = model.predict(negs)
X_scores = np.hstack([scores_pos, scores_neg]).reshape(-1,1)

# Train logistic regression on validation
# Prepare validation similarly
pos_val = X_valid.copy()
negs_val = []
for h, r, t in pos_val:
    corrupt = t
    while corrupt == t:
        corrupt = np.random.choice(all_ents)
    negs_val.append([h, r, corrupt])
negs_val = np.array(negs_val)
X_val = np.vstack([pos_val, negs_val])
y_val = np.hstack([np.ones(len(pos_val)), np.zeros(len(negs_val))])
scores_val = np.hstack([model.predict(pos_val), model.predict(negs_val)]).reshape(-1,1)

clf = LogisticRegression(solver='liblinear')
clf.fit(scores_val, y_val)
print("Trained Logistic Regression on validation scores")

# Evaluate classifier on test
y_pred_prob = clf.predict_proba(X_scores)[:,1]
y_pred = clf.predict(X_scores)
auc = roc_auc_score(y, y_pred_prob)
acc = accuracy_score(y, y_pred)
print(f"Classification AUC: {auc:.4f}, Accuracy: {acc:.4f}")